{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with Data\n",
    "\n",
    "Data is the foundation on which machine learning models are built. Managing data centrally in the cloud, and making it accessible to teams of data scientists who are running experiments and training models on multiple workstations and compute targets is an important part of any professional data science solution.\n",
    "\n",
    "In this lab, you'll explore two Azure Machine Learning objects for working with data: *Datastores*, and *Datasets*.\n",
    "\n",
    "## Before You Start\n",
    "\n",
    "Before you start this lab, ensure that you have completed the *Create an Azure Machine Learning Workspace* and *Create a Compute Instance* tasks in [Lab 1: Getting Started with Azure Machine Learning](./labdocs/Lab01.md). Then open this notebook in Jupyter on your Compute Instance.\n",
    "\n",
    "## Connect to Your Workspace\n",
    "\n",
    "The first thing you need to do is to connect to your workspace using the Azure ML SDK.\n",
    "\n",
    "> **Note**: If you do not have a current authenticated session with your Azure subscription, you'll be prompted to authenticate. Follow the instructions to authenticate using the code provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready to use Azure ML 1.5.0 to work with Hackathon\n"
     ]
    }
   ],
   "source": [
    "import azureml.core\n",
    "from azureml.core import Workspace\n",
    "\n",
    "# Load the workspace from the saved config file\n",
    "ws = Workspace.from_config()\n",
    "print('Ready to use Azure ML {} to work with {}'.format(azureml.core.VERSION, ws.name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work with a Datastore\n",
    "\n",
    "In Azure ML, *datastores* are references to storage locations, such as Azure Storage blob containers. Every workspace has a default datastore - usually the Azure storage blob container that was created with the workspace. If you need to work with data that is stored in different locations, you can add custom datastores to your workspace and set any of them to be the default.\n",
    "\n",
    "### View Datastores\n",
    "\n",
    "Run the following code to determine the datastores in your workspace:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "azureml_globaldatasets - Default = False\n",
      "workspacefilestore - Default = False\n",
      "workspaceblobstore - Default = True\n"
     ]
    }
   ],
   "source": [
    "# Get the default datastore\n",
    "default_ds = ws.get_default_datastore()\n",
    "\n",
    "# Enumerate all datastores, indicating which is the default\n",
    "for ds_name in ws.datastores:\n",
    "    print(ds_name, \"- Default =\", ds_name == default_ds.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also view and manage datastores in your workspace on the Datastores page for your workspace in [Azure ML Studio](https://ml.azure.com).\n",
    "\n",
    "### Upload Data to a Datastore\n",
    "\n",
    "Now that you have determined the available datastores, you can upload files from your local file system to a datastore so that it will be accessible to experiments running in the workspace, regardless of where the experiment script is actually being run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading an estimated of 2 files\n",
      "Uploading ./data/diabetes.csv\n",
      "Uploading ./data/diabetes2.csv\n",
      "Uploaded ./data/diabetes2.csv, 1 files out of an estimated total of 2\n",
      "Uploaded ./data/diabetes.csv, 2 files out of an estimated total of 2\n",
      "Uploaded 2 files\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "$AZUREML_DATAREFERENCE_a53c0422a427409ab267e482d483ec9e"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_ds.upload_files(files=['./data/diabetes.csv', './data/diabetes2.csv'], # Upload the diabetes csv files in /data\n",
    "                       target_path='diabetes-data/', # Put it in a folder path in the datastore\n",
    "                       overwrite=True, # Replace existing files of the same name\n",
    "                       show_progress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a Model from a Datastore\n",
    "\n",
    "When you uploaded the files in the code cell above, note that the code returned a *data reference*. A data reference provides a way to pass the path to a folder in a datastore to a script, regardless of where the script is being run, so that the script can access data in the datastore location.\n",
    "\n",
    "The following code gets a reference to the **diabetes-data** folder where you uploaded the diabetes CSV files, and specifically configures the data reference for *download* - in other words, it can be used to download the contents of the folder to the compute context where the data reference is being used. Downloading data works well for small volumes of data that will be processed on local compute. When working with remote compute, you can also configure a data reference to *mount* the datastore location and read data directly from the data source.\n",
    "\n",
    "> **More Information**: For more details about using datastores, see the [Azure ML documentation](https://docs.microsoft.com/azure/machine-learning/how-to-access-data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$AZUREML_DATAREFERENCE_8d25c9622e9c4723ae3dff654eda1783\n"
     ]
    }
   ],
   "source": [
    "data_ref = default_ds.path('diabetes-data').as_download(path_on_compute='diabetes_data')\n",
    "print(data_ref)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use the data reference in a training script, you must define a parameter for it. Run the following two code cells to create:\n",
    "\n",
    "1. A folder named **diabetes_training_from_datastore**\n",
    "2. A script that trains a classification model by using the training data in all of the CSV files in the folder referenced by the data reference parameter passed to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diabetes_training_from_datastore folder created.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Create a folder for the experiment files\n",
    "experiment_folder = 'diabetes_training_from_datastore'\n",
    "os.makedirs(experiment_folder, exist_ok=True)\n",
    "print(experiment_folder, 'folder created.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing diabetes_training_from_datastore/diabetes_training.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $experiment_folder/diabetes_training.py\n",
    "# Import libraries\n",
    "import os\n",
    "import argparse\n",
    "from azureml.core import Run\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "# Get parameters\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--regularization', type=float, dest='reg_rate', default=0.01, help='regularization rate')\n",
    "parser.add_argument('--data-folder', type=str, dest='data_folder', help='data folder reference')\n",
    "args = parser.parse_args()\n",
    "reg = args.reg_rate\n",
    "\n",
    "# Get the experiment run context\n",
    "run = Run.get_context()\n",
    "\n",
    "# load the diabetes data from the data reference\n",
    "data_folder = args.data_folder\n",
    "print(\"Loading data from\", data_folder)\n",
    "# Load all files and concatenate their contents as a single dataframe\n",
    "all_files = os.listdir(data_folder)\n",
    "diabetes = pd.concat((pd.read_csv(os.path.join(data_folder,csv_file)) for csv_file in all_files))\n",
    "\n",
    "# Separate features and labels\n",
    "X, y = diabetes[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age']].values, diabetes['Diabetic'].values\n",
    "\n",
    "# Split data into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
    "\n",
    "# Train a logistic regression model\n",
    "print('Training a logistic regression model with regularization rate of', reg)\n",
    "run.log('Regularization Rate',  np.float(reg))\n",
    "model = LogisticRegression(C=1/reg, solver=\"liblinear\").fit(X_train, y_train)\n",
    "\n",
    "# calculate accuracy\n",
    "y_hat = model.predict(X_test)\n",
    "acc = np.average(y_hat == y_test)\n",
    "print('Accuracy:', acc)\n",
    "run.log('Accuracy', np.float(acc))\n",
    "\n",
    "# calculate AUC\n",
    "y_scores = model.predict_proba(X_test)\n",
    "auc = roc_auc_score(y_test,y_scores[:,1])\n",
    "print('AUC: ' + str(auc))\n",
    "run.log('AUC', np.float(auc))\n",
    "\n",
    "os.makedirs('outputs', exist_ok=True)\n",
    "# note file saved in the outputs folder is automatically uploaded into experiment record\n",
    "joblib.dump(value=model, filename='outputs/diabetes_model.pkl')\n",
    "\n",
    "run.complete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The script will load the training data from the data reference passed to it as a parameter, so now you just need to set up the script parameters to pass the file reference when we run the experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfa113f3a65440a08d2227533ad9dd51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_UserRunWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', '…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/aml.mini.widget.v1": "{\"status\": \"Completed\", \"workbench_run_details_uri\": \"https://ml.azure.com/experiments/diabetes-training/runs/diabetes-training_1590057747_e3d631de?wsid=/subscriptions/04e58a85-6e14-4823-9261-44c504ab9c03/resourcegroups/Hackathon_Group/workspaces/Hackathon\", \"run_id\": \"diabetes-training_1590057747_e3d631de\", \"run_properties\": {\"run_id\": \"diabetes-training_1590057747_e3d631de\", \"created_utc\": \"2020-05-21T10:42:28.023035Z\", \"properties\": {\"_azureml.ComputeTargetType\": \"local\", \"ContentSnapshotId\": \"e9b654e6-8382-496e-acfb-98add351739f\", \"azureml.git.repository_uri\": \"https://github.com/microsoftdocs/mslearn-aml-labs\", \"mlflow.source.git.repoURL\": \"https://github.com/microsoftdocs/mslearn-aml-labs\", \"azureml.git.branch\": \"master\", \"mlflow.source.git.branch\": \"master\", \"azureml.git.commit\": \"53af8a1588ba0f4e62a4cb7c21fd714ee8fd2feb\", \"mlflow.source.git.commit\": \"53af8a1588ba0f4e62a4cb7c21fd714ee8fd2feb\", \"azureml.git.dirty\": \"True\"}, \"tags\": {}, \"script_name\": null, \"arguments\": null, \"end_time_utc\": \"2020-05-21T10:42:35.306482Z\", \"status\": \"Completed\", \"log_files\": {\"azureml-logs/60_control_log.txt\": \"https://hackathon0664301370.blob.core.windows.net/azureml/ExperimentRun/dcid.diabetes-training_1590057747_e3d631de/azureml-logs/60_control_log.txt?sv=2019-02-02&sr=b&sig=EnfpaTetnIeQZLbzTs58OJF0PiZdUHVrKKokCA3%2BtUc%3D&st=2020-05-21T10%3A32%3A42Z&se=2020-05-21T18%3A42%3A42Z&sp=r\", \"azureml-logs/70_driver_log.txt\": \"https://hackathon0664301370.blob.core.windows.net/azureml/ExperimentRun/dcid.diabetes-training_1590057747_e3d631de/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=jox0WDy2aQwVYi5hM4GmFm08Vxl%2BAW%2Fz2oLm9qqTb%2Bo%3D&st=2020-05-21T10%3A32%3A42Z&se=2020-05-21T18%3A42%3A42Z&sp=r\", \"logs/azureml/8_azureml.log\": \"https://hackathon0664301370.blob.core.windows.net/azureml/ExperimentRun/dcid.diabetes-training_1590057747_e3d631de/logs/azureml/8_azureml.log?sv=2019-02-02&sr=b&sig=P5VBBkiIX6YJdrV9Zh27Qlu0VZ1GD8fywLcoTOKu30k%3D&st=2020-05-21T10%3A32%3A42Z&se=2020-05-21T18%3A42%3A42Z&sp=r\"}, \"log_groups\": [[\"logs/azureml/8_azureml.log\"], [\"azureml-logs/60_control_log.txt\"], [\"azureml-logs/70_driver_log.txt\"]], \"run_duration\": \"0:00:07\"}, \"child_runs\": [], \"children_metrics\": {}, \"run_metrics\": [{\"name\": \"Regularization Rate\", \"run_id\": \"diabetes-training_1590057747_e3d631de\", \"categories\": [0], \"series\": [{\"data\": [0.1]}]}, {\"name\": \"Accuracy\", \"run_id\": \"diabetes-training_1590057747_e3d631de\", \"categories\": [0], \"series\": [{\"data\": [0.7893333333333333]}]}, {\"name\": \"AUC\", \"run_id\": \"diabetes-training_1590057747_e3d631de\", \"categories\": [0], \"series\": [{\"data\": [0.8568655044545174]}]}], \"run_logs\": \"Entering context manager injector. Current time:2020-05-21T10:42:29.732287\\nStarting the daemon thread to refresh tokens in background for process with pid = 8\\nAcquired lockfile /tmp/diabetes-training_1590057747_e3d631de-datastore.lock to downloading input data references\\nDownloading diabetes-data/diabetes.csv\\nDownloading diabetes-data/diabetes2.csv\\nDownloaded diabetes-data/diabetes.csv, 1 files out of an estimated total of 2\\nDownloaded diabetes-data/diabetes2.csv, 2 files out of an estimated total of 2\\nEntering Run History Context Manager.\\nPreparing to call script [ diabetes_training.py ] with arguments: ['--regularization', '0.1', '--data-folder', 'diabetes_data/diabetes-data']\\nAfter variable expansion, calling script [ diabetes_training.py ] with arguments: ['--regularization', '0.1', '--data-folder', 'diabetes_data/diabetes-data']\\n\\nLoading data from diabetes_data/diabetes-data\\nTraining a logistic regression model with regularization rate of 0.1\\nAccuracy: 0.7893333333333333\\nAUC: 0.8568655044545174\\nStarting the daemon thread to refresh tokens in background for process with pid = 8\\n\\n\\nThe experiment completed successfully. Finalizing run...\\nLogging experiment finalizing status in history service.\\nCleaning up all outstanding Run operations, waiting 300.0 seconds\\n2 items cleaning up...\\nCleanup took 0.11294174194335938 seconds\\n\\nRun is completed.\", \"graph\": {}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.5.0\"}, \"loading\": false}"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'runId': 'diabetes-training_1590057747_e3d631de',\n",
       " 'target': 'local',\n",
       " 'status': 'Completed',\n",
       " 'startTimeUtc': '2020-05-21T10:42:28.995222Z',\n",
       " 'endTimeUtc': '2020-05-21T10:42:35.306482Z',\n",
       " 'properties': {'_azureml.ComputeTargetType': 'local',\n",
       "  'ContentSnapshotId': 'e9b654e6-8382-496e-acfb-98add351739f',\n",
       "  'azureml.git.repository_uri': 'https://github.com/microsoftdocs/mslearn-aml-labs',\n",
       "  'mlflow.source.git.repoURL': 'https://github.com/microsoftdocs/mslearn-aml-labs',\n",
       "  'azureml.git.branch': 'master',\n",
       "  'mlflow.source.git.branch': 'master',\n",
       "  'azureml.git.commit': '53af8a1588ba0f4e62a4cb7c21fd714ee8fd2feb',\n",
       "  'mlflow.source.git.commit': '53af8a1588ba0f4e62a4cb7c21fd714ee8fd2feb',\n",
       "  'azureml.git.dirty': 'True'},\n",
       " 'inputDatasets': [],\n",
       " 'runDefinition': {'script': 'diabetes_training.py',\n",
       "  'useAbsolutePath': False,\n",
       "  'arguments': ['--regularization',\n",
       "   '0.1',\n",
       "   '--data-folder',\n",
       "   '$AZUREML_DATAREFERENCE_8d25c9622e9c4723ae3dff654eda1783'],\n",
       "  'sourceDirectoryDataStore': None,\n",
       "  'framework': 'Python',\n",
       "  'communicator': 'None',\n",
       "  'target': 'local',\n",
       "  'dataReferences': {'8d25c9622e9c4723ae3dff654eda1783': {'dataStoreName': 'workspaceblobstore',\n",
       "    'mode': 'Download',\n",
       "    'pathOnDataStore': 'diabetes-data',\n",
       "    'pathOnCompute': 'diabetes_data',\n",
       "    'overwrite': False}},\n",
       "  'data': {},\n",
       "  'jobName': None,\n",
       "  'maxRunDurationSeconds': None,\n",
       "  'nodeCount': 1,\n",
       "  'environment': {'name': 'Experiment diabetes-training Environment',\n",
       "   'version': 'Autosave_2020-05-21T09:39:24Z_2fdf03a9',\n",
       "   'python': {'interpreterPath': 'python',\n",
       "    'userManagedDependencies': False,\n",
       "    'condaDependencies': {'channels': ['anaconda', 'conda-forge'],\n",
       "     'dependencies': ['python=3.6.2',\n",
       "      {'pip': ['azureml-defaults',\n",
       "        'scikit-learn==0.20.3',\n",
       "        'scipy==1.2.1',\n",
       "        'numpy==1.16.2',\n",
       "        'joblib==0.13.2']}],\n",
       "     'name': 'azureml_12c51bdabb987f6db1eeb8e263909841'},\n",
       "    'baseCondaEnvironment': None},\n",
       "   'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'},\n",
       "   'docker': {'baseImage': 'mcr.microsoft.com/azureml/base:intelmpi2018.3-ubuntu16.04',\n",
       "    'baseDockerfile': None,\n",
       "    'baseImageRegistry': {'address': None, 'username': None, 'password': None},\n",
       "    'enabled': True,\n",
       "    'arguments': []},\n",
       "   'spark': {'repositories': [], 'packages': [], 'precachePackages': False},\n",
       "   'inferencingStackVersion': None},\n",
       "  'history': {'outputCollection': True,\n",
       "   'directoriesToWatch': ['logs'],\n",
       "   'snapshotProject': True},\n",
       "  'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment',\n",
       "    'spark.yarn.maxAppAttempts': '1'}},\n",
       "  'parallelTask': {'maxRetriesPerWorker': 0,\n",
       "   'workerCountPerNode': 1,\n",
       "   'terminalExitCodes': None,\n",
       "   'configuration': {}},\n",
       "  'amlCompute': {'name': None,\n",
       "   'vmSize': None,\n",
       "   'retainCluster': False,\n",
       "   'clusterMaxNodeCount': 1},\n",
       "  'tensorflow': {'workerCount': 1, 'parameterServerCount': 1},\n",
       "  'mpi': {'processCountPerNode': 1},\n",
       "  'hdi': {'yarnDeployMode': 'Cluster'},\n",
       "  'containerInstance': {'region': None, 'cpuCores': 2, 'memoryGb': 3.5},\n",
       "  'exposedPorts': None,\n",
       "  'docker': {'useDocker': True,\n",
       "   'sharedVolumes': True,\n",
       "   'shmSize': '2g',\n",
       "   'arguments': []},\n",
       "  'cmk8sCompute': {'configuration': {}},\n",
       "  'itpCompute': {'configuration': {}}},\n",
       " 'logFiles': {'azureml-logs/60_control_log.txt': 'https://hackathon0664301370.blob.core.windows.net/azureml/ExperimentRun/dcid.diabetes-training_1590057747_e3d631de/azureml-logs/60_control_log.txt?sv=2019-02-02&sr=b&sig=cqzGRWRp2VDlbjl3IjjAiyn3e6fVX8t4qKOq4O06UVQ%3D&st=2020-05-21T10%3A32%3A43Z&se=2020-05-21T18%3A42%3A43Z&sp=r',\n",
       "  'azureml-logs/70_driver_log.txt': 'https://hackathon0664301370.blob.core.windows.net/azureml/ExperimentRun/dcid.diabetes-training_1590057747_e3d631de/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=m2zrqBI54Pyg3XJ1oiuvabzsF44y5Vf1hiNxzrN9HtI%3D&st=2020-05-21T10%3A32%3A43Z&se=2020-05-21T18%3A42%3A43Z&sp=r',\n",
       "  'logs/azureml/8_azureml.log': 'https://hackathon0664301370.blob.core.windows.net/azureml/ExperimentRun/dcid.diabetes-training_1590057747_e3d631de/logs/azureml/8_azureml.log?sv=2019-02-02&sr=b&sig=U7Cs0tRMz9NezsGmrHULbXhq4xu0bCLsXGhKoZUfcv0%3D&st=2020-05-21T10%3A32%3A43Z&se=2020-05-21T18%3A42%3A43Z&sp=r'}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.train.sklearn import SKLearn\n",
    "from azureml.core import Experiment\n",
    "from azureml.widgets import RunDetails\n",
    "\n",
    "# Set up the parameters\n",
    "script_params = {\n",
    "    '--regularization': 0.1, # regularization rate\n",
    "    '--data-folder': data_ref # data reference to download files from datastore\n",
    "}\n",
    "\n",
    "\n",
    "# Create an estimator\n",
    "estimator = SKLearn(source_directory=experiment_folder,\n",
    "                    entry_script='diabetes_training.py',\n",
    "                    script_params=script_params,\n",
    "                    compute_target = 'local'\n",
    "                   )\n",
    "\n",
    "# Create an experiment\n",
    "experiment_name = 'diabetes-training'\n",
    "experiment = Experiment(workspace = ws, name = experiment_name)\n",
    "\n",
    "# Run the experiment\n",
    "run = experiment.submit(config=estimator)\n",
    "# Show the run details while running\n",
    "RunDetails(run).show()\n",
    "run.wait_for_completion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first time the experiment is run, it may take some time to set up the Python environment - subsequent runs will be quicker.\n",
    "\n",
    "When the experiment has completed, in the widget, view the **azureml-logs/70_driver_log.txt** output log to verify that the data files were downloaded before the experiment script was run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work with Datasets\n",
    "\n",
    "While you can read data directly from datastores, Azure Machine Learning provides a further abstraction for data in the form of *datasets*. A dataset is a versioned reference to a specific set of data that you may want to use in an experiment. Datasets can be *tabular* or *file*-based.\n",
    "\n",
    "### Create a Tabular Dataset\n",
    "\n",
    "Let's create a dataset from the diabetes data you uploaded to the datastore, and view the first 20 records. In this case, the data is in a structured format in a CSV file, so we'll use a *tabular* dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PatientID</th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>PlasmaGlucose</th>\n",
       "      <th>DiastolicBloodPressure</th>\n",
       "      <th>TricepsThickness</th>\n",
       "      <th>SerumInsulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigree</th>\n",
       "      <th>Age</th>\n",
       "      <th>Diabetic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1354778</td>\n",
       "      <td>0</td>\n",
       "      <td>171</td>\n",
       "      <td>80</td>\n",
       "      <td>34</td>\n",
       "      <td>23</td>\n",
       "      <td>43.509726</td>\n",
       "      <td>1.213191</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1147438</td>\n",
       "      <td>8</td>\n",
       "      <td>92</td>\n",
       "      <td>93</td>\n",
       "      <td>47</td>\n",
       "      <td>36</td>\n",
       "      <td>21.240576</td>\n",
       "      <td>0.158365</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1640031</td>\n",
       "      <td>7</td>\n",
       "      <td>115</td>\n",
       "      <td>47</td>\n",
       "      <td>52</td>\n",
       "      <td>35</td>\n",
       "      <td>41.511523</td>\n",
       "      <td>0.079019</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1883350</td>\n",
       "      <td>9</td>\n",
       "      <td>103</td>\n",
       "      <td>78</td>\n",
       "      <td>25</td>\n",
       "      <td>304</td>\n",
       "      <td>29.582192</td>\n",
       "      <td>1.282870</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1424119</td>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>59</td>\n",
       "      <td>27</td>\n",
       "      <td>35</td>\n",
       "      <td>42.604536</td>\n",
       "      <td>0.549542</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1619297</td>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "      <td>92</td>\n",
       "      <td>9</td>\n",
       "      <td>253</td>\n",
       "      <td>19.724160</td>\n",
       "      <td>0.103424</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1660149</td>\n",
       "      <td>0</td>\n",
       "      <td>133</td>\n",
       "      <td>47</td>\n",
       "      <td>19</td>\n",
       "      <td>227</td>\n",
       "      <td>21.941357</td>\n",
       "      <td>0.174160</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1458769</td>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>87</td>\n",
       "      <td>43</td>\n",
       "      <td>36</td>\n",
       "      <td>18.277723</td>\n",
       "      <td>0.236165</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1201647</td>\n",
       "      <td>8</td>\n",
       "      <td>80</td>\n",
       "      <td>95</td>\n",
       "      <td>33</td>\n",
       "      <td>24</td>\n",
       "      <td>26.624929</td>\n",
       "      <td>0.443947</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1403912</td>\n",
       "      <td>1</td>\n",
       "      <td>72</td>\n",
       "      <td>31</td>\n",
       "      <td>40</td>\n",
       "      <td>42</td>\n",
       "      <td>36.889576</td>\n",
       "      <td>0.103944</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1943830</td>\n",
       "      <td>1</td>\n",
       "      <td>88</td>\n",
       "      <td>86</td>\n",
       "      <td>11</td>\n",
       "      <td>58</td>\n",
       "      <td>43.225041</td>\n",
       "      <td>0.230285</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1824483</td>\n",
       "      <td>3</td>\n",
       "      <td>94</td>\n",
       "      <td>96</td>\n",
       "      <td>31</td>\n",
       "      <td>36</td>\n",
       "      <td>21.294479</td>\n",
       "      <td>0.259020</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1848869</td>\n",
       "      <td>5</td>\n",
       "      <td>114</td>\n",
       "      <td>101</td>\n",
       "      <td>43</td>\n",
       "      <td>70</td>\n",
       "      <td>36.495320</td>\n",
       "      <td>0.079190</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1669231</td>\n",
       "      <td>7</td>\n",
       "      <td>110</td>\n",
       "      <td>82</td>\n",
       "      <td>16</td>\n",
       "      <td>44</td>\n",
       "      <td>36.089293</td>\n",
       "      <td>0.281276</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1683688</td>\n",
       "      <td>0</td>\n",
       "      <td>148</td>\n",
       "      <td>58</td>\n",
       "      <td>11</td>\n",
       "      <td>179</td>\n",
       "      <td>39.192076</td>\n",
       "      <td>0.160829</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1738587</td>\n",
       "      <td>3</td>\n",
       "      <td>109</td>\n",
       "      <td>77</td>\n",
       "      <td>46</td>\n",
       "      <td>61</td>\n",
       "      <td>19.847312</td>\n",
       "      <td>0.204345</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1884264</td>\n",
       "      <td>3</td>\n",
       "      <td>106</td>\n",
       "      <td>64</td>\n",
       "      <td>25</td>\n",
       "      <td>51</td>\n",
       "      <td>29.044573</td>\n",
       "      <td>0.589188</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1485251</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>53</td>\n",
       "      <td>15</td>\n",
       "      <td>226</td>\n",
       "      <td>29.786192</td>\n",
       "      <td>0.203824</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1536832</td>\n",
       "      <td>8</td>\n",
       "      <td>117</td>\n",
       "      <td>39</td>\n",
       "      <td>32</td>\n",
       "      <td>164</td>\n",
       "      <td>21.230996</td>\n",
       "      <td>0.089363</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1438701</td>\n",
       "      <td>3</td>\n",
       "      <td>102</td>\n",
       "      <td>100</td>\n",
       "      <td>25</td>\n",
       "      <td>289</td>\n",
       "      <td>42.185720</td>\n",
       "      <td>0.175593</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    PatientID  Pregnancies  PlasmaGlucose  DiastolicBloodPressure  \\\n",
       "0     1354778            0            171                      80   \n",
       "1     1147438            8             92                      93   \n",
       "2     1640031            7            115                      47   \n",
       "3     1883350            9            103                      78   \n",
       "4     1424119            1             85                      59   \n",
       "5     1619297            0             82                      92   \n",
       "6     1660149            0            133                      47   \n",
       "7     1458769            0             67                      87   \n",
       "8     1201647            8             80                      95   \n",
       "9     1403912            1             72                      31   \n",
       "10    1943830            1             88                      86   \n",
       "11    1824483            3             94                      96   \n",
       "12    1848869            5            114                     101   \n",
       "13    1669231            7            110                      82   \n",
       "14    1683688            0            148                      58   \n",
       "15    1738587            3            109                      77   \n",
       "16    1884264            3            106                      64   \n",
       "17    1485251            1            156                      53   \n",
       "18    1536832            8            117                      39   \n",
       "19    1438701            3            102                     100   \n",
       "\n",
       "    TricepsThickness  SerumInsulin        BMI  DiabetesPedigree  Age  Diabetic  \n",
       "0                 34            23  43.509726          1.213191   21         0  \n",
       "1                 47            36  21.240576          0.158365   23         0  \n",
       "2                 52            35  41.511523          0.079019   23         0  \n",
       "3                 25           304  29.582192          1.282870   43         1  \n",
       "4                 27            35  42.604536          0.549542   22         0  \n",
       "5                  9           253  19.724160          0.103424   26         0  \n",
       "6                 19           227  21.941357          0.174160   21         0  \n",
       "7                 43            36  18.277723          0.236165   26         0  \n",
       "8                 33            24  26.624929          0.443947   53         1  \n",
       "9                 40            42  36.889576          0.103944   26         0  \n",
       "10                11            58  43.225041          0.230285   22         0  \n",
       "11                31            36  21.294479          0.259020   23         0  \n",
       "12                43            70  36.495320          0.079190   38         1  \n",
       "13                16            44  36.089293          0.281276   25         0  \n",
       "14                11           179  39.192076          0.160829   45         0  \n",
       "15                46            61  19.847312          0.204345   21         1  \n",
       "16                25            51  29.044573          0.589188   42         1  \n",
       "17                15           226  29.786192          0.203824   41         1  \n",
       "18                32           164  21.230996          0.089363   25         0  \n",
       "19                25           289  42.185720          0.175593   43         1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.core import Dataset\n",
    "\n",
    "# Get the default datastore\n",
    "default_ds = ws.get_default_datastore()\n",
    "\n",
    "#Create a tabular dataset from the path on the datastore (this may take a short while)\n",
    "tab_data_set = Dataset.Tabular.from_delimited_files(path=(default_ds, 'diabetes-data/*.csv'))\n",
    "\n",
    "# Display the first 20 rows as a Pandas dataframe\n",
    "tab_data_set.take(20).to_pandas_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see in the code above, it's easy to convert a tabular dataset to a Pandas dataframe, enabling you to work with the data using common python techniques.\n",
    "\n",
    "### Create a File Dataset\n",
    "\n",
    "The dataset you created is a *tabular* dataset that can be read as a dataframe containing all of the data in the structured files that are included in the dataset definition. This works well for tabular data, but in some machine learning scenarios you might need to work with data that is unstructured; or you may simply want to handle reading the data from files in your own code. To accomplish this, you can use a *file* dataset, which creates a list of file paths in a virtual mount point, which you can use to read the data in the files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/diabetes.csv\n",
      "/diabetes2.csv\n"
     ]
    }
   ],
   "source": [
    "#Create a file dataset from the path on the datastore (this may take a short while)\n",
    "file_data_set = Dataset.File.from_files(path=(default_ds, 'diabetes-data/*.csv'))\n",
    "\n",
    "# Get the files in the dataset\n",
    "for file_path in file_data_set.to_path():\n",
    "    print(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Register Datasets\n",
    "\n",
    "Now that you have created datasets that reference the diabetes data, you can register them to make them easily accessible to any experiment being run in the workspace.\n",
    "\n",
    "We'll register the tabular dataset as **diabetes dataset**, and the file dataset as **diabetes files**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets registered\n"
     ]
    }
   ],
   "source": [
    "# Register the tabular dataset\n",
    "try:\n",
    "    tab_data_set = tab_data_set.register(workspace=ws, \n",
    "                                        name='diabetes dataset',\n",
    "                                        description='diabetes data',\n",
    "                                        tags = {'format':'CSV'},\n",
    "                                        create_new_version=True)\n",
    "except Exception as ex:\n",
    "    print(ex)\n",
    "\n",
    "# Register the file dataset\n",
    "try:\n",
    "    file_data_set = file_data_set.register(workspace=ws,\n",
    "                                            name='diabetes file dataset',\n",
    "                                            description='diabetes files',\n",
    "                                            tags = {'format':'CSV'},\n",
    "                                            create_new_version=True)\n",
    "except Exception as ex:\n",
    "    print(ex)\n",
    "\n",
    "print('Datasets registered')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can view and manage datasets on the **Datasets** page for your workspace in [Azure ML Studio](https://ml.azure.com). You cal also get a list of datasets from the workspace object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets:\n",
      "\t diabetes file dataset version 1\n",
      "\t diabetes dataset version 1\n",
      "\t Diabetes version 1\n"
     ]
    }
   ],
   "source": [
    "print(\"Datasets:\")\n",
    "for dataset_name in list(ws.datasets.keys()):\n",
    "    dataset = Dataset.get_by_name(ws, dataset_name)\n",
    "    print(\"\\t\", dataset.name, 'version', dataset.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ability to version datasets enables you to redefine datasets without breaking existing experiments or pipelines that rely on previous definitions. By default, the latest version of a named dataset is returned, but you can retrieve a specific version of a dataset by specifying the version number, like this:\n",
    "\n",
    "```python\n",
    "dataset_v1 = Dataset.get_by_name(ws, 'diabetes dataset', version = 1)\n",
    "```\n",
    "\n",
    "\n",
    "### Train a Model from a Tabular Dataset\n",
    "\n",
    "Now that you have datasets, you're ready to start training models from them. You can pass datasets to scripts as *inputs* in the estimator being used to run the script.\n",
    "\n",
    "Run the following two code cells to create:\n",
    "\n",
    "1. A folder named **diabetes_training_from_tab_dataset**\n",
    "2. A script that trains a classification model by using a tabular dataset that is passed to is as an *input*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diabetes_training_from_tab_dataset folder created\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Create a folder for the experiment files\n",
    "experiment_folder = 'diabetes_training_from_tab_dataset'\n",
    "os.makedirs(experiment_folder, exist_ok=True)\n",
    "print(experiment_folder, 'folder created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing diabetes_training_from_tab_dataset/diabetes_training.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $experiment_folder/diabetes_training.py\n",
    "# Import libraries\n",
    "import argparse\n",
    "from azureml.core import Run\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "# Set regularization hyperparameter (passed as an argument to the script)\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--regularization', type=float, dest='reg_rate', default=0.01, help='regularization rate')\n",
    "args = parser.parse_args()\n",
    "reg = args.reg_rate\n",
    "\n",
    "# Get the experiment run context\n",
    "run = Run.get_context()\n",
    "\n",
    "# load the diabetes data (passed as an input dataset)\n",
    "print(\"Loading Data...\")\n",
    "diabetes = run.input_datasets['diabetes'].to_pandas_dataframe()\n",
    "\n",
    "# Separate features and labels\n",
    "X, y = diabetes[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age']].values, diabetes['Diabetic'].values\n",
    "\n",
    "# Split data into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
    "\n",
    "# Train a logistic regression model\n",
    "print('Training a logistic regression model with regularization rate of', reg)\n",
    "run.log('Regularization Rate',  np.float(reg))\n",
    "model = LogisticRegression(C=1/reg, solver=\"liblinear\").fit(X_train, y_train)\n",
    "\n",
    "# calculate accuracy\n",
    "y_hat = model.predict(X_test)\n",
    "acc = np.average(y_hat == y_test)\n",
    "print('Accuracy:', acc)\n",
    "run.log('Accuracy', np.float(acc))\n",
    "\n",
    "# calculate AUC\n",
    "y_scores = model.predict_proba(X_test)\n",
    "auc = roc_auc_score(y_test,y_scores[:,1])\n",
    "print('AUC: ' + str(auc))\n",
    "run.log('AUC', np.float(auc))\n",
    "\n",
    "os.makedirs('outputs', exist_ok=True)\n",
    "# note file saved in the outputs folder is automatically uploaded into experiment record\n",
    "joblib.dump(value=model, filename='outputs/diabetes_model.pkl')\n",
    "\n",
    "run.complete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can create an estimator to run the script, and define a named *input* for the training dataset, which is read by the script.\n",
    "\n",
    "> **Note**: The **Dataset** class is defined in the **azureml-dataprep** package (which is installed with the SDK), and this package includes optional support for **pandas** (which is used by the **to_pandas_dataframe()** method, so you need to include this package in the environment where the training experiment will be run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df18e62cf6e44dda83c832d05ff96988",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_UserRunWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', '…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/aml.mini.widget.v1": "{\"status\": \"Completed\", \"workbench_run_details_uri\": \"https://ml.azure.com/experiments/diabetes-training/runs/diabetes-training_1590058323_8ab4cd2a?wsid=/subscriptions/04e58a85-6e14-4823-9261-44c504ab9c03/resourcegroups/Hackathon_Group/workspaces/Hackathon\", \"run_id\": \"diabetes-training_1590058323_8ab4cd2a\", \"run_properties\": {\"run_id\": \"diabetes-training_1590058323_8ab4cd2a\", \"created_utc\": \"2020-05-21T10:52:04.212821Z\", \"properties\": {\"_azureml.ComputeTargetType\": \"local\", \"ContentSnapshotId\": \"92eb409f-fa2a-4728-b44d-6bc6583e9f2d\", \"azureml.git.repository_uri\": \"https://github.com/microsoftdocs/mslearn-aml-labs\", \"mlflow.source.git.repoURL\": \"https://github.com/microsoftdocs/mslearn-aml-labs\", \"azureml.git.branch\": \"master\", \"mlflow.source.git.branch\": \"master\", \"azureml.git.commit\": \"53af8a1588ba0f4e62a4cb7c21fd714ee8fd2feb\", \"mlflow.source.git.commit\": \"53af8a1588ba0f4e62a4cb7c21fd714ee8fd2feb\", \"azureml.git.dirty\": \"True\"}, \"tags\": {}, \"script_name\": null, \"arguments\": null, \"end_time_utc\": \"2020-05-21T10:54:57.847238Z\", \"status\": \"Completed\", \"log_files\": {\"azureml-logs/60_control_log.txt\": \"https://hackathon0664301370.blob.core.windows.net/azureml/ExperimentRun/dcid.diabetes-training_1590058323_8ab4cd2a/azureml-logs/60_control_log.txt?sv=2019-02-02&sr=b&sig=kWDLe9E4WCwOcVIAKAI3yekLRwVoPjWakr6I1SgvRhU%3D&st=2020-05-21T10%3A45%3A05Z&se=2020-05-21T18%3A55%3A05Z&sp=r\", \"azureml-logs/70_driver_log.txt\": \"https://hackathon0664301370.blob.core.windows.net/azureml/ExperimentRun/dcid.diabetes-training_1590058323_8ab4cd2a/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=1PROBKlHgwP92PS3Vi3OWOMGKY68hLyLs3H6Va18VV0%3D&st=2020-05-21T10%3A45%3A05Z&se=2020-05-21T18%3A55%3A05Z&sp=r\", \"logs/azureml/8_azureml.log\": \"https://hackathon0664301370.blob.core.windows.net/azureml/ExperimentRun/dcid.diabetes-training_1590058323_8ab4cd2a/logs/azureml/8_azureml.log?sv=2019-02-02&sr=b&sig=POFS2kvNmdAC8Sl2TGsXcVp8Ex8wTzypDHTTOFl5Lks%3D&st=2020-05-21T10%3A45%3A05Z&se=2020-05-21T18%3A55%3A05Z&sp=r\"}, \"log_groups\": [[\"logs/azureml/8_azureml.log\"], [\"azureml-logs/60_control_log.txt\"], [\"azureml-logs/70_driver_log.txt\"]], \"run_duration\": \"0:02:53\"}, \"child_runs\": [], \"children_metrics\": {}, \"run_metrics\": [{\"name\": \"Regularization Rate\", \"run_id\": \"diabetes-training_1590058323_8ab4cd2a\", \"categories\": [0], \"series\": [{\"data\": [0.1]}]}, {\"name\": \"Accuracy\", \"run_id\": \"diabetes-training_1590058323_8ab4cd2a\", \"categories\": [0], \"series\": [{\"data\": [0.7893333333333333]}]}, {\"name\": \"AUC\", \"run_id\": \"diabetes-training_1590058323_8ab4cd2a\", \"categories\": [0], \"series\": [{\"data\": [0.8568632924585982]}]}], \"run_logs\": \"Entering context manager injector. Current time:2020-05-21T10:54:49.313847\\nStarting the daemon thread to refresh tokens in background for process with pid = 8\\nEntering Run History Context Manager.\\nPreparing to call script [ diabetes_training.py ] with arguments: ['--regularization', '0.1']\\nAfter variable expansion, calling script [ diabetes_training.py ] with arguments: ['--regularization', '0.1']\\n\\nLoading Data...\\nTraining a logistic regression model with regularization rate of 0.1\\nAccuracy: 0.7893333333333333\\nAUC: 0.8568632924585982\\nStarting the daemon thread to refresh tokens in background for process with pid = 8\\n\\n\\nThe experiment completed successfully. Finalizing run...\\nLogging experiment finalizing status in history service.\\nCleaning up all outstanding Run operations, waiting 300.0 seconds\\n2 items cleaning up...\\nCleanup took 0.1291816234588623 seconds\\n\\nRun is completed.\", \"graph\": {}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.5.0\"}, \"loading\": false}"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'runId': 'diabetes-training_1590058323_8ab4cd2a',\n",
       " 'target': 'local',\n",
       " 'status': 'Finalizing',\n",
       " 'startTimeUtc': '2020-05-21T10:54:48.536766Z',\n",
       " 'properties': {'_azureml.ComputeTargetType': 'local',\n",
       "  'ContentSnapshotId': '92eb409f-fa2a-4728-b44d-6bc6583e9f2d',\n",
       "  'azureml.git.repository_uri': 'https://github.com/microsoftdocs/mslearn-aml-labs',\n",
       "  'mlflow.source.git.repoURL': 'https://github.com/microsoftdocs/mslearn-aml-labs',\n",
       "  'azureml.git.branch': 'master',\n",
       "  'mlflow.source.git.branch': 'master',\n",
       "  'azureml.git.commit': '53af8a1588ba0f4e62a4cb7c21fd714ee8fd2feb',\n",
       "  'mlflow.source.git.commit': '53af8a1588ba0f4e62a4cb7c21fd714ee8fd2feb',\n",
       "  'azureml.git.dirty': 'True'},\n",
       " 'inputDatasets': [{'dataset': {'id': 'f5a1df5e-0d6f-4be9-b74e-e169f7b17b54'}, 'consumptionDetails': {'type': 'RunInput', 'inputName': 'diabetes', 'mechanism': 'Direct'}}],\n",
       " 'runDefinition': {'script': 'diabetes_training.py',\n",
       "  'useAbsolutePath': False,\n",
       "  'arguments': ['--regularization', '0.1'],\n",
       "  'sourceDirectoryDataStore': None,\n",
       "  'framework': 'Python',\n",
       "  'communicator': 'None',\n",
       "  'target': 'local',\n",
       "  'dataReferences': {},\n",
       "  'data': {'diabetes': {'dataLocation': {'dataset': {'id': 'f5a1df5e-0d6f-4be9-b74e-e169f7b17b54'},\n",
       "     'dataPath': None},\n",
       "    'createOutputDirectories': False,\n",
       "    'mechanism': 'Direct',\n",
       "    'environmentVariableName': 'diabetes',\n",
       "    'pathOnCompute': None,\n",
       "    'overwrite': False}},\n",
       "  'jobName': None,\n",
       "  'maxRunDurationSeconds': None,\n",
       "  'nodeCount': 1,\n",
       "  'environment': {'name': 'Experiment diabetes-training Environment',\n",
       "   'version': 'Autosave_2020-05-21T10:52:03Z_7054033d',\n",
       "   'python': {'interpreterPath': 'python',\n",
       "    'userManagedDependencies': False,\n",
       "    'condaDependencies': {'channels': ['anaconda', 'conda-forge'],\n",
       "     'dependencies': ['python=3.6.2',\n",
       "      {'pip': ['azureml-dataprep[pandas]',\n",
       "        'azureml-defaults',\n",
       "        'scikit-learn==0.20.3',\n",
       "        'scipy==1.2.1',\n",
       "        'numpy==1.16.2',\n",
       "        'joblib==0.13.2']}],\n",
       "     'name': 'azureml_3fc31fe37ae4feefa22d0e0765e1084b'},\n",
       "    'baseCondaEnvironment': None},\n",
       "   'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'},\n",
       "   'docker': {'baseImage': 'mcr.microsoft.com/azureml/base:intelmpi2018.3-ubuntu16.04',\n",
       "    'baseDockerfile': None,\n",
       "    'baseImageRegistry': {'address': None, 'username': None, 'password': None},\n",
       "    'enabled': True,\n",
       "    'arguments': []},\n",
       "   'spark': {'repositories': [], 'packages': [], 'precachePackages': False},\n",
       "   'inferencingStackVersion': None},\n",
       "  'history': {'outputCollection': True,\n",
       "   'directoriesToWatch': ['logs'],\n",
       "   'snapshotProject': True},\n",
       "  'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment',\n",
       "    'spark.yarn.maxAppAttempts': '1'}},\n",
       "  'parallelTask': {'maxRetriesPerWorker': 0,\n",
       "   'workerCountPerNode': 1,\n",
       "   'terminalExitCodes': None,\n",
       "   'configuration': {}},\n",
       "  'amlCompute': {'name': None,\n",
       "   'vmSize': None,\n",
       "   'retainCluster': False,\n",
       "   'clusterMaxNodeCount': 1},\n",
       "  'tensorflow': {'workerCount': 1, 'parameterServerCount': 1},\n",
       "  'mpi': {'processCountPerNode': 1},\n",
       "  'hdi': {'yarnDeployMode': 'Cluster'},\n",
       "  'containerInstance': {'region': None, 'cpuCores': 2, 'memoryGb': 3.5},\n",
       "  'exposedPorts': None,\n",
       "  'docker': {'useDocker': True,\n",
       "   'sharedVolumes': True,\n",
       "   'shmSize': '2g',\n",
       "   'arguments': []},\n",
       "  'cmk8sCompute': {'configuration': {}},\n",
       "  'itpCompute': {'configuration': {}}},\n",
       " 'logFiles': {'azureml-logs/60_control_log.txt': 'https://hackathon0664301370.blob.core.windows.net/azureml/ExperimentRun/dcid.diabetes-training_1590058323_8ab4cd2a/azureml-logs/60_control_log.txt?sv=2019-02-02&sr=b&sig=jk0O6cZuHOXiOVjxxdJgQOqTQ%2FdYjipBJHO%2BL5fC%2BsM%3D&st=2020-05-21T10%3A44%3A56Z&se=2020-05-21T18%3A54%3A56Z&sp=r',\n",
       "  'azureml-logs/70_driver_log.txt': 'https://hackathon0664301370.blob.core.windows.net/azureml/ExperimentRun/dcid.diabetes-training_1590058323_8ab4cd2a/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=eLumm8jyIYdHmTPynjspT5qRT8hrHy0mJsmBY0gEB40%3D&st=2020-05-21T10%3A44%3A56Z&se=2020-05-21T18%3A54%3A56Z&sp=r',\n",
       "  'logs/azureml/8_azureml.log': 'https://hackathon0664301370.blob.core.windows.net/azureml/ExperimentRun/dcid.diabetes-training_1590058323_8ab4cd2a/logs/azureml/8_azureml.log?sv=2019-02-02&sr=b&sig=XXbPU4rrntQK13X%2B%2F7ORDe2Pe1raQxkw4Ld%2Fb8do%2FUA%3D&st=2020-05-21T10%3A44%3A56Z&se=2020-05-21T18%3A54%3A56Z&sp=r'}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.train.sklearn import SKLearn\n",
    "from azureml.core import Experiment\n",
    "from azureml.widgets import RunDetails\n",
    "\n",
    "# Set the script parameters\n",
    "script_params = {\n",
    "    '--regularization': 0.1\n",
    "}\n",
    "\n",
    "# Get the training dataset\n",
    "diabetes_ds = ws.datasets.get(\"diabetes dataset\")\n",
    "\n",
    "# Create an estimator\n",
    "estimator = SKLearn(source_directory=experiment_folder,\n",
    "                    entry_script='diabetes_training.py',\n",
    "                    script_params=script_params,\n",
    "                    compute_target = 'local',\n",
    "                    inputs=[diabetes_ds.as_named_input('diabetes')], # Pass the Dataset object as an input...\n",
    "                    pip_packages=['azureml-dataprep[pandas]'] # ...so you need the dataprep package\n",
    "                   )\n",
    "\n",
    "# Create an experiment\n",
    "experiment_name = 'diabetes-training'\n",
    "experiment = Experiment(workspace = ws, name = experiment_name)\n",
    "\n",
    "# Run the experiment\n",
    "run = experiment.submit(config=estimator)\n",
    "# Show the run details while running\n",
    "RunDetails(run).show()\n",
    "run.wait_for_completion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first time the experiment is run, it may take some time to set up the Python environment - subsequent runs will be quicker.\n",
    "\n",
    "When the experiment has completed, in the widget, view the **azureml-logs/70_driver_log.txt** output log and the metrics generated by the run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a Model from a File Dataset\n",
    "\n",
    "You've seen how to train a model using training data in a *tabular* dataset; but what about a *file* dataset?\n",
    "\n",
    "When you're using a file dataset, the dataset input passed to the script represents a mount point containing file paths. How you read the data from these files depends on the kind of data in the files and what you want to do with it. In the case of the diabetes CSV files, you can use the Python **glob** module to create a list of files in the virtual mount point defined by the dataset, and read them all into Pandas dataframes that are concatenated into a single dataframe.\n",
    "\n",
    "Run the following two code cells to create:\n",
    "\n",
    "1. A folder named **diabetes_training_from_file_dataset**\n",
    "2. A script that trains a classification model by using a file dataset that is passed to is as an *input*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diabetes_training_from_file_dataset folder created\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Create a folder for the experiment files\n",
    "experiment_folder = 'diabetes_training_from_file_dataset'\n",
    "os.makedirs(experiment_folder, exist_ok=True)\n",
    "print(experiment_folder, 'folder created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing diabetes_training_from_file_dataset/diabetes_training.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $experiment_folder/diabetes_training.py\n",
    "# Import libraries\n",
    "import argparse\n",
    "from azureml.core import Workspace, Dataset, Experiment, Run\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "import glob\n",
    "\n",
    "# Set regularization hyperparameter (passed as an argument to the script)\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--regularization', type=float, dest='reg_rate', default=0.01, help='regularization rate')\n",
    "args = parser.parse_args()\n",
    "reg = args.reg_rate\n",
    "\n",
    "# Get the experiment run context\n",
    "run = Run.get_context()\n",
    "\n",
    "# load the diabetes dataset\n",
    "print(\"Loading Data...\")\n",
    "data_path = run.input_datasets['diabetes'] # Get the training data from the estimator input\n",
    "all_files = glob.glob(data_path + \"/*.csv\")\n",
    "diabetes = pd.concat((pd.read_csv(f) for f in all_files))\n",
    "\n",
    "# Separate features and labels\n",
    "X, y = diabetes[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age']].values, diabetes['Diabetic'].values\n",
    "\n",
    "# Split data into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
    "\n",
    "# Train a logistic regression model\n",
    "print('Training a logistic regression model with regularization rate of', reg)\n",
    "run.log('Regularization Rate',  np.float(reg))\n",
    "model = LogisticRegression(C=1/reg, solver=\"liblinear\").fit(X_train, y_train)\n",
    "\n",
    "# calculate accuracy\n",
    "y_hat = model.predict(X_test)\n",
    "acc = np.average(y_hat == y_test)\n",
    "print('Accuracy:', acc)\n",
    "run.log('Accuracy', np.float(acc))\n",
    "\n",
    "# calculate AUC\n",
    "y_scores = model.predict_proba(X_test)\n",
    "auc = roc_auc_score(y_test,y_scores[:,1])\n",
    "print('AUC: ' + str(auc))\n",
    "run.log('AUC', np.float(auc))\n",
    "\n",
    "os.makedirs('outputs', exist_ok=True)\n",
    "# note file saved in the outputs folder is automatically uploaded into experiment record\n",
    "joblib.dump(value=model, filename='outputs/diabetes_model.pkl')\n",
    "\n",
    "run.complete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we need to change the way we pass the dataset to the estimator - it needs to define a mount point from which the script can read the files. For large volumes of data, you'd generally use the **as_mount** method to stream the files directly from the dataset source; but when running on local compute (as we are in this example), you need to use the **as_download** option to download the dataset files to a local folder.\n",
    "\n",
    "Also, since the **Dataset** class is defined in the **azureml-dataprep** package, we need to include that in the experiment environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e3e37bcbcb84da2a9e7041a23ae14f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_UserRunWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', '…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/aml.mini.widget.v1": "{\"status\": \"Completed\", \"workbench_run_details_uri\": \"https://ml.azure.com/experiments/diabetes-training/runs/diabetes-training_1590058589_85b94c71?wsid=/subscriptions/04e58a85-6e14-4823-9261-44c504ab9c03/resourcegroups/Hackathon_Group/workspaces/Hackathon\", \"run_id\": \"diabetes-training_1590058589_85b94c71\", \"run_properties\": {\"run_id\": \"diabetes-training_1590058589_85b94c71\", \"created_utc\": \"2020-05-21T10:56:30.077054Z\", \"properties\": {\"_azureml.ComputeTargetType\": \"local\", \"ContentSnapshotId\": \"af8fa940-3cd1-44ed-9e29-437477b55502\", \"azureml.git.repository_uri\": \"https://github.com/microsoftdocs/mslearn-aml-labs\", \"mlflow.source.git.repoURL\": \"https://github.com/microsoftdocs/mslearn-aml-labs\", \"azureml.git.branch\": \"master\", \"mlflow.source.git.branch\": \"master\", \"azureml.git.commit\": \"53af8a1588ba0f4e62a4cb7c21fd714ee8fd2feb\", \"mlflow.source.git.commit\": \"53af8a1588ba0f4e62a4cb7c21fd714ee8fd2feb\", \"azureml.git.dirty\": \"True\"}, \"tags\": {}, \"script_name\": null, \"arguments\": null, \"end_time_utc\": \"2020-05-21T10:56:40.686782Z\", \"status\": \"Completed\", \"log_files\": {\"azureml-logs/60_control_log.txt\": \"https://hackathon0664301370.blob.core.windows.net/azureml/ExperimentRun/dcid.diabetes-training_1590058589_85b94c71/azureml-logs/60_control_log.txt?sv=2019-02-02&sr=b&sig=Ct27s8784onbOllkiN2ltfJWNLcyA8WtczfxIGpD8T8%3D&st=2020-05-21T10%3A46%3A46Z&se=2020-05-21T18%3A56%3A46Z&sp=r\", \"azureml-logs/70_driver_log.txt\": \"https://hackathon0664301370.blob.core.windows.net/azureml/ExperimentRun/dcid.diabetes-training_1590058589_85b94c71/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=dTJZfKNqqSzU2zaSM7GShLCwx%2BxlXZUDLKK%2Bljk8w4U%3D&st=2020-05-21T10%3A46%3A46Z&se=2020-05-21T18%3A56%3A46Z&sp=r\", \"logs/azureml/9_azureml.log\": \"https://hackathon0664301370.blob.core.windows.net/azureml/ExperimentRun/dcid.diabetes-training_1590058589_85b94c71/logs/azureml/9_azureml.log?sv=2019-02-02&sr=b&sig=l9dHs8KzKO2nqpukDBex47DmCcO8XlBH1JcEszbCtYI%3D&st=2020-05-21T10%3A46%3A46Z&se=2020-05-21T18%3A56%3A46Z&sp=r\"}, \"log_groups\": [[\"logs/azureml/9_azureml.log\"], [\"azureml-logs/60_control_log.txt\"], [\"azureml-logs/70_driver_log.txt\"]], \"run_duration\": \"0:00:10\"}, \"child_runs\": [], \"children_metrics\": {}, \"run_metrics\": [{\"name\": \"Regularization Rate\", \"run_id\": \"diabetes-training_1590058589_85b94c71\", \"categories\": [0], \"series\": [{\"data\": [0.1]}]}, {\"name\": \"Accuracy\", \"run_id\": \"diabetes-training_1590058589_85b94c71\", \"categories\": [0], \"series\": [{\"data\": [0.7893333333333333]}]}, {\"name\": \"AUC\", \"run_id\": \"diabetes-training_1590058589_85b94c71\", \"categories\": [0], \"series\": [{\"data\": [0.8568655044545174]}]}], \"run_logs\": \"Entering context manager injector. Current time:2020-05-21T10:56:31.698018\\nInitialize DatasetContextManager.\\nStarting the daemon thread to refresh tokens in background for process with pid = 9\\nEnter __enter__ of DatasetContextManager\\nSDK version: azureml-core==1.5.0.post4 azureml-dataprep==1.6.3\\nProcessing 'diabetes'\\nProcessing dataset FileDataset\\n{\\n  \\\"source\\\": [\\n    \\\"('workspaceblobstore', 'diabetes-data/*.csv')\\\"\\n  ],\\n  \\\"definition\\\": [\\n    \\\"GetDatastoreFiles\\\"\\n  ],\\n  \\\"registration\\\": {\\n    \\\"id\\\": \\\"49d8aa1a-f563-436b-98b8-e20fd4dca05b\\\",\\n    \\\"name\\\": \\\"diabetes file dataset\\\",\\n    \\\"version\\\": 1,\\n    \\\"description\\\": \\\"diabetes files\\\",\\n    \\\"tags\\\": {\\n      \\\"format\\\": \\\"CSV\\\"\\n    },\\n    \\\"workspace\\\": \\\"Workspace.create(name='Hackathon', subscription_id='04e58a85-6e14-4823-9261-44c504ab9c03', resource_group='Hackathon_Group')\\\"\\n  }\\n}\\nDownloading diabetes to diabetes_data\\nDownloaded diabetes to diabetes_data\\nExit __enter__ of DatasetContextManager\\nEntering Run History Context Manager.\\nPreparing to call script [ diabetes_training.py ] with arguments: ['--regularization', '0.1']\\nAfter variable expansion, calling script [ diabetes_training.py ] with arguments: ['--regularization', '0.1']\\n\\nLoading Data...\\nTraining a logistic regression model with regularization rate of 0.1\\nAccuracy: 0.7893333333333333\\nAUC: 0.8568655044545174\\nStarting the daemon thread to refresh tokens in background for process with pid = 9\\n\\n\\nThe experiment completed successfully. Finalizing run...\\nLogging experiment finalizing status in history service.\\nCleaning up all outstanding Run operations, waiting 300.0 seconds\\n2 items cleaning up...\\nCleanup took 0.12824678421020508 seconds\\nEnter __exit__ of DatasetContextManager\\nExit __exit__ of DatasetContextManager\\n\\nRun is completed.\", \"graph\": {}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.5.0\"}, \"loading\": false}"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'runId': 'diabetes-training_1590058589_85b94c71',\n",
       " 'target': 'local',\n",
       " 'status': 'Completed',\n",
       " 'startTimeUtc': '2020-05-21T10:56:30.976575Z',\n",
       " 'endTimeUtc': '2020-05-21T10:56:40.686782Z',\n",
       " 'properties': {'_azureml.ComputeTargetType': 'local',\n",
       "  'ContentSnapshotId': 'af8fa940-3cd1-44ed-9e29-437477b55502',\n",
       "  'azureml.git.repository_uri': 'https://github.com/microsoftdocs/mslearn-aml-labs',\n",
       "  'mlflow.source.git.repoURL': 'https://github.com/microsoftdocs/mslearn-aml-labs',\n",
       "  'azureml.git.branch': 'master',\n",
       "  'mlflow.source.git.branch': 'master',\n",
       "  'azureml.git.commit': '53af8a1588ba0f4e62a4cb7c21fd714ee8fd2feb',\n",
       "  'mlflow.source.git.commit': '53af8a1588ba0f4e62a4cb7c21fd714ee8fd2feb',\n",
       "  'azureml.git.dirty': 'True'},\n",
       " 'inputDatasets': [{'dataset': {'id': '49d8aa1a-f563-436b-98b8-e20fd4dca05b'}, 'consumptionDetails': {'type': 'RunInput', 'inputName': 'diabetes', 'mechanism': 'Download', 'pathOnCompute': 'diabetes_data'}}],\n",
       " 'runDefinition': {'script': 'diabetes_training.py',\n",
       "  'useAbsolutePath': False,\n",
       "  'arguments': ['--regularization', '0.1'],\n",
       "  'sourceDirectoryDataStore': None,\n",
       "  'framework': 'Python',\n",
       "  'communicator': 'None',\n",
       "  'target': 'local',\n",
       "  'dataReferences': {},\n",
       "  'data': {'diabetes': {'dataLocation': {'dataset': {'id': '49d8aa1a-f563-436b-98b8-e20fd4dca05b'},\n",
       "     'dataPath': None},\n",
       "    'createOutputDirectories': False,\n",
       "    'mechanism': 'Download',\n",
       "    'environmentVariableName': 'diabetes',\n",
       "    'pathOnCompute': 'diabetes_data',\n",
       "    'overwrite': False}},\n",
       "  'jobName': None,\n",
       "  'maxRunDurationSeconds': None,\n",
       "  'nodeCount': 1,\n",
       "  'environment': {'name': 'Experiment diabetes-training Environment',\n",
       "   'version': 'Autosave_2020-05-21T10:52:03Z_7054033d',\n",
       "   'python': {'interpreterPath': 'python',\n",
       "    'userManagedDependencies': False,\n",
       "    'condaDependencies': {'channels': ['anaconda', 'conda-forge'],\n",
       "     'dependencies': ['python=3.6.2',\n",
       "      {'pip': ['azureml-dataprep[pandas]',\n",
       "        'azureml-defaults',\n",
       "        'scikit-learn==0.20.3',\n",
       "        'scipy==1.2.1',\n",
       "        'numpy==1.16.2',\n",
       "        'joblib==0.13.2']}],\n",
       "     'name': 'azureml_3fc31fe37ae4feefa22d0e0765e1084b'},\n",
       "    'baseCondaEnvironment': None},\n",
       "   'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'},\n",
       "   'docker': {'baseImage': 'mcr.microsoft.com/azureml/base:intelmpi2018.3-ubuntu16.04',\n",
       "    'baseDockerfile': None,\n",
       "    'baseImageRegistry': {'address': None, 'username': None, 'password': None},\n",
       "    'enabled': True,\n",
       "    'arguments': []},\n",
       "   'spark': {'repositories': [], 'packages': [], 'precachePackages': False},\n",
       "   'inferencingStackVersion': None},\n",
       "  'history': {'outputCollection': True,\n",
       "   'directoriesToWatch': ['logs'],\n",
       "   'snapshotProject': True},\n",
       "  'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment',\n",
       "    'spark.yarn.maxAppAttempts': '1'}},\n",
       "  'parallelTask': {'maxRetriesPerWorker': 0,\n",
       "   'workerCountPerNode': 1,\n",
       "   'terminalExitCodes': None,\n",
       "   'configuration': {}},\n",
       "  'amlCompute': {'name': None,\n",
       "   'vmSize': None,\n",
       "   'retainCluster': False,\n",
       "   'clusterMaxNodeCount': 1},\n",
       "  'tensorflow': {'workerCount': 1, 'parameterServerCount': 1},\n",
       "  'mpi': {'processCountPerNode': 1},\n",
       "  'hdi': {'yarnDeployMode': 'Cluster'},\n",
       "  'containerInstance': {'region': None, 'cpuCores': 2, 'memoryGb': 3.5},\n",
       "  'exposedPorts': None,\n",
       "  'docker': {'useDocker': True,\n",
       "   'sharedVolumes': True,\n",
       "   'shmSize': '2g',\n",
       "   'arguments': []},\n",
       "  'cmk8sCompute': {'configuration': {}},\n",
       "  'itpCompute': {'configuration': {}}},\n",
       " 'logFiles': {'azureml-logs/60_control_log.txt': 'https://hackathon0664301370.blob.core.windows.net/azureml/ExperimentRun/dcid.diabetes-training_1590058589_85b94c71/azureml-logs/60_control_log.txt?sv=2019-02-02&sr=b&sig=%2BUXch3zxiQbrSNVObDIyrc4dzag0khBw%2BN8G7GJm3UI%3D&st=2020-05-21T10%3A46%3A41Z&se=2020-05-21T18%3A56%3A41Z&sp=r',\n",
       "  'azureml-logs/70_driver_log.txt': 'https://hackathon0664301370.blob.core.windows.net/azureml/ExperimentRun/dcid.diabetes-training_1590058589_85b94c71/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=sRAcTYEHJ%2FoI9E7NgCquVq0yExxSfUrh%2FxTYQ7CArNk%3D&st=2020-05-21T10%3A46%3A41Z&se=2020-05-21T18%3A56%3A41Z&sp=r',\n",
       "  'logs/azureml/9_azureml.log': 'https://hackathon0664301370.blob.core.windows.net/azureml/ExperimentRun/dcid.diabetes-training_1590058589_85b94c71/logs/azureml/9_azureml.log?sv=2019-02-02&sr=b&sig=sLxpm9jq6OrmuwEAhWhLMYmrkHmX%2B5UHF5R3Ki5EMzo%3D&st=2020-05-21T10%3A46%3A41Z&se=2020-05-21T18%3A56%3A41Z&sp=r'}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.train.sklearn import SKLearn\n",
    "from azureml.core import Experiment\n",
    "from azureml.widgets import RunDetails\n",
    "\n",
    "# Set the script parameters\n",
    "script_params = {\n",
    "    '--regularization': 0.1\n",
    "}\n",
    "\n",
    "# Get the training dataset\n",
    "diabetes_ds = ws.datasets.get(\"diabetes file dataset\")\n",
    "\n",
    "# Create an estimator\n",
    "estimator = SKLearn(source_directory=experiment_folder,\n",
    "                    entry_script='diabetes_training.py',\n",
    "                    script_params=script_params,\n",
    "                    compute_target = 'local',\n",
    "                    inputs=[diabetes_ds.as_named_input('diabetes').as_download(path_on_compute='diabetes_data')], # Pass the Dataset object as an input\n",
    "                    pip_packages=['azureml-dataprep[pandas]'] # so we need the dataprep package\n",
    "                   )\n",
    "\n",
    "# Create an experiment\n",
    "experiment_name = 'diabetes-training'\n",
    "experiment = Experiment(workspace = ws, name = experiment_name)\n",
    "\n",
    "# Run the experiment\n",
    "run = experiment.submit(config=estimator)\n",
    "# Show the run details while running\n",
    "RunDetails(run).show()\n",
    "run.wait_for_completion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the experiment has completed, in the widget, view the **azureml-logs/70_driver_log.txt** output log to verify that the file dataset was processed and the data files downloaded."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
